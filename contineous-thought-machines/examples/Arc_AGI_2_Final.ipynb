{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ad2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install mediapy\n",
    "!pip install safetensors\n",
    "!pip install numpy\n",
    "# For advanced optimizations, consider installing the following:\n",
    "!pip install accelerate\n",
    "!pip install diffusers\n",
    "!pip install xformers\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36949333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42322d",
   "metadata": {},
   "source": [
    "This section contains the set-up components for training the ctm model with the byte-level encoder with binary patches, ctm processing with synpase system set to multi-objective, \n",
    "\n",
    "and binary patches from the ctm (after 20 rounds of COT thinking) refined and trained with MCMC to encourage the model to have reasoning steps closely related to the best answer, \n",
    "\n",
    "Each epoch is saved as a safetensor checkpoint to preserve training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06056c40",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Dependency Installation Notes\n",
    "# -----------------------------------------------------------------------------\n",
    " The following dependencies are required. Please install them in your Python environment,\n",
    " for example, using pip:\n",
    "\n",
    " pip install mediapy\n",
    " pip install torch\n",
    " pip install safetensors\n",
    " pip install numpy\n",
    "\n",
    " For advanced optimizations, consider installing the following:\n",
    " pip install flash-attn --no-build-isolation\n",
    " pip install deepspeed\n",
    " pip install accelerate\n",
    " pip install xformers\n",
    "\n",
    " It's recommended to use a virtual environment.\n",
    " -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Dependency Setup & Imports\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Please ensure all required dependencies are installed.\")\n",
    "print(\"Base dependencies: torchaudio, imageio, mediapy, torch, safetensors, numpy\")\n",
    "print(\"Optional optimization dependencies: flash-attn, deepspeed, accelerate, xformers\")\n",
    "print(\"See comments at the top of the script for installation commands.\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define the base directory for saving checkpoints\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"Base Checkpoint Directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Attempt to import optional dependencies and set flags\n",
    "\n",
    "try:\n",
    "    from accelerate import Accelerator\n",
    "    from accelerate.utils import DistributedDataParallelKwargs\n",
    "    HAS_ACCELERATE = True\n",
    "    print(\"Accelerate library found.\")\n",
    "except ImportError:\n",
    "    HAS_ACCELERATE = False\n",
    "    print(\"Accelerate library not found. Some features like multi-GPU training might be limited.\")\n",
    "\n",
    "try:\n",
    "    import xformers.ops as xops\n",
    "    HAS_XFORMERS = True\n",
    "    print(\"xFormers library found.\")\n",
    "except ImportError:\n",
    "    HAS_XFORMERS = False\n",
    "    print(\"xFormers library not found.\")\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# OPTIMIZATION: Advanced optimization imports\n",
    "\n",
    "try:\n",
    "    from accelerate import Accelerator\n",
    "    ACCELERATE_AVAILABLE = True\n",
    "    print(\"âœ… Accelerate available\")\n",
    "except ImportError:\n",
    "    ACCELERATE_AVAILABLE = False\n",
    "    print(\"âš ï¸ Accelerate not available\")\n",
    "\n",
    "try:\n",
    "    import xformers\n",
    "    import xformers.ops\n",
    "    XFORMERS_AVAILABLE = True\n",
    "    print(\"âœ… xFormers available - Expected 1.5-2x speedup\")\n",
    "except ImportError:\n",
    "    XFORMERS_AVAILABLE = False\n",
    "    print(\"âš ï¸ xFormers not available\")\n",
    "\n",
    "# Try to import mediapy, fallback if not available\n",
    "try:\n",
    "    import mediapy\n",
    "    MEDIAPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MEDIAPY_AVAILABLE = False\n",
    "    print(\"Warning: mediapy not available. GIF preview will be limited.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from safetensors.torch import save_model, load_model\n",
    "    SAFETENSORS_AVAILABLE = True\n",
    "    print(\"âœ… safetensors available for model checkpointing.\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Warning: safetensors not found. Checkpoints will not be saved in safetensors format.\")\n",
    "    save_model = None\n",
    "    load_model = None\n",
    "    SAFETENSORS_AVAILABLE = False\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.checkpoint import checkpoint  # OPTIMIZATION: Gradient checkpointing\n",
    "\n",
    "print(\"\\nðŸš€ OPTIMIZATION STATUS:\")\n",
    "print(f\"  âš¡ torch.compile: {'âœ…' if hasattr(torch, 'compile') else 'âŒ'}\")\n",
    "print(f\"  ðŸ“ˆ Accelerate: {'âœ…' if ACCELERATE_AVAILABLE else 'âŒ'}\")\n",
    "print(f\"  âš¡ xFormers: {'âœ…' if XFORMERS_AVAILABLE else 'âŒ'}\")\n",
    "\n",
    "# Add module paths\n",
    "# IMPORTANT: These paths assume the script is run from a directory where '..'\n",
    "# correctly points to the project root relative to 'models' and 'tasks' folders.\n",
    "# Adjust if your script is located elsewhere.\n",
    "print(\"\\n-----------------------------------------------------------------------------\")\n",
    "print(\"Setting up module paths...\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "try:\n",
    "    current_script_path = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError: # __file__ is not defined in interactive shells, use os.getcwd()\n",
    "    current_script_path = os.getcwd()\n",
    "\n",
    "module_paths = [\n",
    "    os.path.abspath(os.path.join(current_script_path, '..', 'models')),\n",
    "    os.path.abspath(os.path.join(current_script_path, '..'))\n",
    "]\n",
    "module_paths.append(os.path.abspath('contineous-thought-machines'))\n",
    "for path in module_paths:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "        print(f\"Added to sys.path: {path}\")\n",
    "\n",
    "# Import Enhanced CTM with diffusion control and all optimizations.\n",
    "# OPTIMIZED_CTM_CONFIG_ARC will be defined below if imports are successful.\n",
    "print(\"\\n-----------------------------------------------------------------------------\")\n",
    "print(\"Importing CTM and Dataloader modules...\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "EnhancedCTMDiffusion = None # Initialize to None\n",
    "ENHANCED_MCMC_AVAILABLE = False # Initialize\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from models.ctm_Diffusion_NEWNEW import (\n",
    "        EnhancedCTMDiffusion,\n",
    "        EnhancedCTMConfig,\n",
    "        CTMControlledDiffusionProcessor,\n",
    "        FrequencyDomainAwareAttention,\n",
    "        IntegrationFlowHiPASampler,\n",
    "        CTMIntegrationFlowTrainer,\n",
    "    )\n",
    "    print(\"âœ“ Successfully imported EnhancedCTMDiffusion with ALL GPU optimizations\")\n",
    "    print(\"  - Integration Flow one-step generation\")\n",
    "    print(\"  - Task-Aware HiPA frequency enhancement\")\n",
    "    print(\"  - CTM-guided diffusion control\")\n",
    "    print(\"  - GPU memory optimizations\")\n",
    "    print(\"  - Mixed precision training support\")\n",
    "\n",
    "\n",
    "except ImportError as e_ctm:\n",
    "    print(f\"âŒ Error importing Enhanced CTM or related components: {e_ctm}\")\n",
    "    print(\"   Please ensure 'models/ctm_Diffusion_NEWNEW_.py' components exist and are accessible.\")\n",
    "    EnhancedCTMDiffusion = None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration for Integrated Diffusion CTM\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n-----------------------------------------------------------------------------\")\n",
    "print(\"Initializing Configuration for Integrated Diffusion CTM\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ðŸš€ OPTIMIZATION 1: Enhanced Mixed Precision Training Setup (FP16/BF16)\n",
    "USE_MIXED_PRECISION = torch.cuda.is_available() and hasattr(torch.cuda, 'amp') and device.type == 'cuda'\n",
    "USE_BFLOAT16 = USE_MIXED_PRECISION and torch.cuda.is_bf16_supported()\n",
    "\n",
    "autocast_dtype = torch.float32 # Default\n",
    "if USE_MIXED_PRECISION:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    if USE_BFLOAT16:\n",
    "        scaler = torch.amp.GradScaler(\"cuda\", enabled=True)\n",
    "        autocast_dtype = torch.bfloat16\n",
    "        print(\"âœ… Mixed precision training enabled (BF16) - Expected ~2x speedup\")\n",
    "    else:\n",
    "        scaler = torch.amp.GradScaler(\"cuda\", enabled=True)\n",
    "        autocast_dtype = torch.float16\n",
    "        print(\"âœ… Mixed precision training enabled (FP16) - Expected ~2x speedup\")\n",
    "else:\n",
    "    scaler = None\n",
    "    class dummy_autocast:\n",
    "        def __enter__(self): return None\n",
    "        def __exit__(self, exc_type, exc_val, exc_tb): return False\n",
    "    autocast = dummy_autocast\n",
    "    autocast_dtype = torch.float32\n",
    "    print(\"âš ï¸ Mixed precision training not available (CPU or older GPU or torch.cuda.amp not found)\")\n",
    "\n",
    "\n",
    "# ðŸš€ OPTIMIZATION 2: Gradient Accumulation Configuration\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "MAX_GRAD_NORM = 1.0\n",
    "\n",
    "# ðŸš€ OPTIMIZATION 4: Data Loading Optimizations\n",
    "OPTIMIZED_DATALOADER_CONFIG = {\n",
    "    'num_workers': min(8, os.cpu_count() if os.cpu_count() else 1),\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "    'persistent_workers': True if min(8, os.cpu_count() if os.cpu_count() else 1) > 0 else False,\n",
    "    'prefetch_factor': 4 if min(8, os.cpu_count() if os.cpu_count() else 1) > 0 else None,\n",
    "}\n",
    "\n",
    "# General Training Parameters (can be overridden by specific phases)\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4180a",
   "metadata": {},
   "source": [
    "# Injected MCMC Components and EnhancedCTMFenchelYoungIntegration Initialization\n",
    "\n",
    "This notebook contains the Python code for MCMC components, including ARC-specific output spaces and an enhanced Fenchel-Young integration layer, structured for use in a Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ad7ca",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "All necessary libraries and modules are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a60f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import Optional, Callable, Tuple, Dict, Any, List, Union\n",
    "from dataclasses import dataclass, field\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings # For ARCGridOutputSpace warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea1006",
   "metadata": {},
   "source": [
    "## 2. Utility Functions (from `models.utils`)\n",
    "Helper functions used across various modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb03888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coord_dim(x, scaled=True):\n",
    "    \"\"\"\n",
    "    Adds a final dimension to the tensor representing 2D coordinates.\n",
    "    \"\"\"\n",
    "    B, H, W = x.shape\n",
    "    x_coords = torch.arange(W, device=x.device, dtype=x.dtype).repeat(H, 1)\n",
    "    y_coords = torch.arange(H, device=x.device, dtype=x.dtype).unsqueeze(-1).repeat(1, W)\n",
    "    if scaled:\n",
    "        x_coords = x_coords / (W - 1) if W > 1 else torch.zeros_like(x_coords)\n",
    "        y_coords = y_coords / (H - 1) if H > 1 else torch.zeros_like(y_coords)\n",
    "    coords = torch.stack((x_coords, y_coords), dim=-1)\n",
    "    coords = coords.unsqueeze(0) \n",
    "    coords = coords.repeat(B, 1, 1, 1) \n",
    "    return coords\n",
    "\n",
    "def compute_normalized_entropy(logits, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Calculates the normalized entropy of a PyTorch tensor of logits along the \n",
    "    final dimension.\n",
    "    \"\"\"\n",
    "    preds = F.softmax(logits, dim=-1)\n",
    "    log_preds = torch.log_softmax(logits, dim=-1)\n",
    "    entropy = -torch.sum(preds * log_preds, dim=-1)\n",
    "    num_classes = preds.shape[-1]\n",
    "    if num_classes <= 1: # Avoid log(1)=0 or log(0)\n",
    "        return torch.zeros_like(entropy)\n",
    "    max_entropy = torch.log(torch.tensor(num_classes, dtype=torch.float32, device=logits.device))\n",
    "    if max_entropy == 0: # Should only happen if num_classes is 1\n",
    "        return torch.zeros_like(entropy)\n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    if len(logits.shape) > 2 and reduction == 'mean':\n",
    "        normalized_entropy = normalized_entropy.flatten(1).mean(-1)\n",
    "    return normalized_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f2785",
   "metadata": {},
   "source": [
    "## 3. Core Modules (from `models.modules`)\n",
    "Custom neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478e0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperLinear(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dims,\n",
    "                 out_dims,\n",
    "                 N,\n",
    "                 T=1.0,\n",
    "                 do_norm=False,\n",
    "                 dropout=0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.in_dims = in_dims\n",
    "        self.layernorm = nn.LayerNorm(in_dims, elementwise_affine=True) if do_norm else nn.Identity()\n",
    "        self.do_norm = do_norm\n",
    "        self.register_parameter('w1', nn.Parameter(\n",
    "            torch.empty((in_dims, out_dims, N)).uniform_(\n",
    "                -1/math.sqrt(in_dims + out_dims),\n",
    "                 1/math.sqrt(in_dims + out_dims)\n",
    "            ), requires_grad=True)\n",
    "        )\n",
    "        self.register_parameter('b1', nn.Parameter(torch.zeros((1, N, out_dims)), requires_grad=True))\n",
    "        self.register_parameter('T', nn.Parameter(torch.Tensor([T]))) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(x)\n",
    "        out = self.layernorm(out)\n",
    "        out = torch.einsum('BDM,MHD->BDH', out, self.w1) + self.b1\n",
    "        out = out.squeeze(-1) / self.T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254063c",
   "metadata": {},
   "source": [
    "## 4. MCMC Interpretability Solver Components (from `models.mcmc_interpretability_solver`)\n",
    "Dataclasses and hooks for tracking and interpreting MCMC processes and solver states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e5b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ThoughtStep:\n",
    "    step_id: int\n",
    "    layer_name: str\n",
    "    input_state: Optional[torch.Tensor] = None\n",
    "    output_state: Optional[torch.Tensor] = None\n",
    "    attention_weights: Optional[torch.Tensor] = None\n",
    "    mcmc_samples: Optional[torch.Tensor] = None\n",
    "    confidence_score: float = 0.0\n",
    "    reasoning_vector: Optional[torch.Tensor] = None\n",
    "    energy_landscape: Dict[str, float] = field(default_factory=dict)\n",
    "    correction_ratio: Optional[float] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class ReasoningChain:\n",
    "    input_data: Optional[torch.Tensor] = None\n",
    "    thought_steps: List[ThoughtStep] = field(default_factory=list)\n",
    "    final_output: Optional[torch.Tensor] = None\n",
    "    confidence_trajectory: List[float] = field(default_factory=list)\n",
    "    decision_points: List[int] = field(default_factory=list)\n",
    "    reasoning_summary: str = \"\"\n",
    "    convergence_metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    solver_diagnostics: List[Dict[str, Any]] = field(default_factory=list)\n",
    "\n",
    "class MCMCInterpretabilityHook:\n",
    "    def __init__(self, layer_name: str):\n",
    "        self.layer_name = layer_name\n",
    "        self.activations: List[Dict[str, Any]] = []\n",
    "        self.gradients: List[torch.Tensor] = []\n",
    "        self.attention_maps: List[Optional[torch.Tensor]] = []\n",
    "        self.mcmc_states: List[Optional[torch.Tensor]] = []\n",
    "        self.energy_values: List[float] = []\n",
    "        self.correction_ratios: List[Optional[float]] = []\n",
    "        self.solver_diagnostics: List[Dict[str, Any]] = []\n",
    "\n",
    "\n",
    "    def forward_hook(self, module, input_data, output_data):\n",
    "        input_tensor = input_data[0] if isinstance(input_data, tuple) else input_data\n",
    "        self.activations.append({\n",
    "            'input': input_tensor.detach().clone() if torch.is_tensor(input_tensor) else input_tensor,\n",
    "            'output': output_data.detach().clone() if torch.is_tensor(output_data) else output_data,\n",
    "            'layer': self.layer_name,\n",
    "            'timestamp': len(self.activations)\n",
    "        })\n",
    "        if hasattr(module, 'mcmc_samples') and module.mcmc_samples is not None:\n",
    "            self.mcmc_states.append(module.mcmc_samples.detach().clone())\n",
    "        if hasattr(module, 'attention_weights') and module.attention_weights is not None:\n",
    "            self.attention_maps.append(module.attention_weights.detach().clone())\n",
    "        if hasattr(module, 'correction_ratios_log') and module.correction_ratios_log: # Assuming a log attribute\n",
    "            self.correction_ratios.append(module.correction_ratios_log[-1])\n",
    "        if hasattr(module, 'solver_diagnostics_log') and module.solver_diagnostics_log: # Assuming a log attribute\n",
    "            diagnostics = module.solver_diagnostics_log[-1]\n",
    "            self.solver_diagnostics.append(diagnostics)\n",
    "            if 'last_objective_value' in diagnostics:\n",
    "                self.energy_values.append(diagnostics['last_objective_value'])\n",
    "    \n",
    "    def backward_hook(self, module, grad_input, grad_output):\n",
    "        if grad_output and grad_output[0] is not None:\n",
    "            self.gradients.append(grad_output[0].detach().clone())\n",
    "\n",
    "class BlackBoxSolver:\n",
    "    def __init__(self, model: nn.Module, device: str = 'cpu'): # Default to CPU if not specified\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.hooks: Dict[str, MCMCInterpretabilityHook] = {}\n",
    "        self.reasoning_chains: List[ReasoningChain] = []\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        for name, module in self.model.named_modules():\n",
    "            if any(keyword in name.lower() for keyword in ['mcmc', 'enhanced', 'correction', 'fenchel', 'oracle']):\n",
    "                if name not in self.hooks:\n",
    "                    hook = MCMCInterpretabilityHook(name)\n",
    "                    self.hooks[name] = hook\n",
    "                    module.register_forward_hook(hook.forward_hook)\n",
    "    \n",
    "    def clear_hooks_data(self):\n",
    "        for hook in self.hooks.values():\n",
    "            hook.activations.clear()\n",
    "            hook.gradients.clear()\n",
    "            hook.attention_maps.clear()\n",
    "            hook.mcmc_states.clear()\n",
    "            hook.energy_values.clear()\n",
    "            hook.correction_ratios.clear()\n",
    "            hook.solver_diagnostics.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44430d41",
   "metadata": {},
   "source": [
    "## 5. Base MCMC Components (from `models.fenchel_young_mcmc`)\n",
    "Core classes for MCMC sampling, including configuration, temperature scheduling, and output space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df631065",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCMCConfig:\n",
    "    num_chains: int = 3\n",
    "    chain_length: int = 20\n",
    "    burn_in: int = 5\n",
    "    temperature_schedule: str = \"geometric\"\n",
    "    initial_temp: float = 10.0\n",
    "    final_temp: float = 1.0\n",
    "    decay_rate: float = 0.995\n",
    "    neighborhood_radius: int = 1 # This is a general parameter, interpretation depends on OutputSpace\n",
    "    initialization_method: str = \"persistent\"\n",
    "\n",
    "class TemperatureScheduler:\n",
    "    @staticmethod\n",
    "    def geometric(initial_temp: float, decay_rate: float, final_temp: float):\n",
    "        def schedule(step: int) -> float:\n",
    "            return max(initial_temp * (decay_rate ** step), final_temp)\n",
    "        return schedule\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(initial_temp: float, final_temp: float, total_steps: int):\n",
    "        def schedule(step: int) -> float:\n",
    "            progress = min(step / total_steps, 1.0) if total_steps > 0 else 1.0\n",
    "            return initial_temp * (1 - progress) + final_temp * progress\n",
    "        return schedule\n",
    "\n",
    "    @staticmethod\n",
    "    def constant(temperature: float):\n",
    "        def schedule(step: int) -> float:\n",
    "            return temperature\n",
    "        return schedule\n",
    "\n",
    "class DiscreteOutputSpace:\n",
    "    def __init__(self, dimension: int):\n",
    "        self.dimension = dimension\n",
    "        self._full_output_space_generated = False\n",
    "        self.output_space: List[torch.Tensor] = []\n",
    "        if self.dimension <= 4: \n",
    "            try:\n",
    "                self.output_space = self._generate_space()\n",
    "                self._full_output_space_generated = True\n",
    "            except (NotImplementedError, ValueError):\n",
    "                self.output_space = []\n",
    "\n",
    "    def _generate_space(self) -> List[torch.Tensor]:\n",
    "        raise NotImplementedError(\"Subclasses must implement _generate_space or rely on _generate_random_member_directly\")\n",
    "\n",
    "    def get_available_neighborhood_strategies(self, state: Optional[torch.Tensor] = None) -> List[str]:\n",
    "        raise NotImplementedError(\"Subclasses must implement get_available_neighborhood_strategies\")\n",
    "\n",
    "    def get_neighbors(self, state: torch.Tensor, strategy_name: str, **strategy_params) -> List[torch.Tensor]:\n",
    "        raise NotImplementedError(\"Subclasses must implement get_neighbors\")\n",
    "\n",
    "    def get_proposal_prob(self, current_state: torch.Tensor, proposed_state: torch.Tensor, strategy_name: str, **strategy_params) -> float:\n",
    "        neighbors = self.get_neighbors(current_state, strategy_name, **strategy_params)\n",
    "        if not neighbors: return 0.0\n",
    "        is_neighbor = any(torch.allclose(neighbor, proposed_state) for neighbor in neighbors)\n",
    "        return (1.0 / len(neighbors)) if is_neighbor else 0.0\n",
    "    \n",
    "    def _generate_random_member_directly(self) -> Optional[torch.Tensor]:\n",
    "        return None\n",
    "\n",
    "    def random_state(self) -> torch.Tensor:\n",
    "        direct_sample = self._generate_random_member_directly()\n",
    "        if direct_sample is not None:\n",
    "            return direct_sample\n",
    "        if self._full_output_space_generated and self.output_space:\n",
    "            return random.choice(self.output_space).clone()\n",
    "        if not self.output_space and not self._full_output_space_generated:\n",
    "            try:\n",
    "                self.output_space = self._generate_space()\n",
    "                self._full_output_space_generated = True\n",
    "                if self.output_space:\n",
    "                    return random.choice(self.output_space).clone()\n",
    "            except (NotImplementedError, ValueError) as e:\n",
    "                raise RuntimeError(f\"Cannot generate random_state for {self.__class__.__name__} (dim {self.dimension}). Error: {e}\")\n",
    "        if not self.output_space:\n",
    "             raise RuntimeError(f\"Output space empty for {self.__class__.__name__} (dim {self.dimension}). Cannot sample random_state.\")\n",
    "        return random.choice(self.output_space).clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd282aa",
   "metadata": {},
   "source": [
    "## 6. ARC Grid Output Space\n",
    "A specific implementation of `DiscreteOutputSpace` for ARC-like grid environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8b7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCGridOutputSpace(DiscreteOutputSpace):\n",
    "    def __init__(self, dimension: int, grid_shape: Tuple[int, int], num_symbols: int):\n",
    "        super().__init__(dimension)\n",
    "        self.grid_shape = grid_shape\n",
    "        self.num_symbols = num_symbols\n",
    "        if dimension != grid_shape[0] * grid_shape[1]:\n",
    "            raise ValueError(f\"Dimension ({dimension}) must match grid_shape ({grid_shape[0]}*{grid_shape[1]}={grid_shape[0]*grid_shape[1]})\")\n",
    "\n",
    "    def _generate_random_member_directly(self) -> Optional[torch.Tensor]:\n",
    "        random_grid = torch.randint(0, self.num_symbols, self.grid_shape, dtype=torch.long)\n",
    "        return random_grid.view(-1).float()\n",
    "\n",
    "    def get_available_neighborhood_strategies(self, state: Optional[torch.Tensor] = None) -> List[str]:\n",
    "        return [\"flip_one_cell_value\", \"swap_two_cells\"]\n",
    "\n",
    "    def get_neighbors(self, state: torch.Tensor, strategy_name: str, **strategy_params) -> List[torch.Tensor]:\n",
    "        neighbors = []\n",
    "        state_grid = state.view(self.grid_shape).long()\n",
    "\n",
    "        if strategy_name == \"flip_one_cell_value\":\n",
    "            num_neighbors_to_generate = strategy_params.get('num_flips', min(5, self.dimension))\n",
    "            for _ in range(num_neighbors_to_generate):\n",
    "                neighbor_grid = state_grid.clone()\n",
    "                row = random.randint(0, self.grid_shape[0] - 1)\n",
    "                col = random.randint(0, self.grid_shape[1] - 1)\n",
    "                original_value = neighbor_grid[row, col].item()\n",
    "                \n",
    "                if self.num_symbols <= 1:\n",
    "                    new_value = original_value\n",
    "                else:\n",
    "                    new_value = random.randint(0, self.num_symbols - 1)\n",
    "                    while new_value == original_value:\n",
    "                        new_value = random.randint(0, self.num_symbols - 1)\n",
    "                neighbor_grid[row, col] = new_value\n",
    "                neighbors.append(neighbor_grid.view(-1).float())\n",
    "        \n",
    "        elif strategy_name == \"swap_two_cells\":\n",
    "            num_neighbors_to_generate = strategy_params.get('num_swaps', min(5, self.dimension // 2 if self.dimension >=2 else 0))\n",
    "            for _ in range(num_neighbors_to_generate):\n",
    "                if self.dimension < 2: break\n",
    "                neighbor_grid = state_grid.clone()\n",
    "                r1, c1 = random.randint(0, self.grid_shape[0] - 1), random.randint(0, self.grid_shape[1] - 1)\n",
    "                r2, c2 = random.randint(0, self.grid_shape[0] - 1), random.randint(0, self.grid_shape[1] - 1)\n",
    "                while r1 == r2 and c1 == c2:\n",
    "                    r2, c2 = random.randint(0, self.grid_shape[0] - 1), random.randint(0, self.grid_shape[1] - 1)\n",
    "                \n",
    "                val1 = neighbor_grid[r1,c1].item()\n",
    "                neighbor_grid[r1,c1] = neighbor_grid[r2,c2].item()\n",
    "                neighbor_grid[r2,c2] = val1\n",
    "                neighbors.append(neighbor_grid.view(-1).float())\n",
    "        else:\n",
    "            warnings.warn(f\"Unknown strategy: {strategy_name} for ARCGridOutputSpace. Returning empty neighbor list.\")\n",
    "        return neighbors\n",
    "\n",
    "    def _generate_space(self) -> List[torch.Tensor]:\n",
    "        if self.dimension > 6:\n",
    "            warnings.warn(f\"Full space generation for ARCGridOutputSpace with dimension {self.dimension} is too large. Returning empty list.\")\n",
    "            return []\n",
    "        return super()._generate_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5fd584",
   "metadata": {},
   "source": [
    "## 7. Enhanced MCMC Layers and Fenchel-Young Integration\n",
    "Includes `ExactOptimizationOracle`, MCMC samplers (`CorrectionRatioMCMC`, `LargeNeighborhoodSearchMCMC`), and the main `EnhancedCTMFenchelYoungIntegration` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcbd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactOptimizationOracle:\n",
    "    def __init__(self, output_space: DiscreteOutputSpace, phi_network: Optional[nn.Module] = None, model: Optional[nn.Module] = None):\n",
    "        self.output_space = output_space\n",
    "        self.phi_network = phi_network\n",
    "        self.solver_state: Dict[str, Any] = {\n",
    "            'last_solution': None, 'last_objective_value': None,\n",
    "            'num_evaluations': 0, 'optimization_history': []\n",
    "        }\n",
    "\n",
    "    def solve(self, theta: torch.Tensor, neighborhood: Optional[List[torch.Tensor]] = None) -> Optional[torch.Tensor]:\n",
    "        search_space = neighborhood\n",
    "        if search_space is None:\n",
    "            if hasattr(self.output_space, '_generate_random_member_directly') and not self.output_space.output_space:\n",
    "                search_space = [self.output_space._generate_random_member_directly() for _ in range(min(self.output_space.dimension, 20))]\n",
    "                search_space = [s for s in search_space if s is not None]\n",
    "            else:\n",
    "                search_space = self.output_space.output_space\n",
    "\n",
    "        if not search_space: return None\n",
    "\n",
    "        best_solution = None\n",
    "        best_value = float('-inf')\n",
    "        \n",
    "        for candidate_idx, candidate_state_maybe_none in enumerate(search_space):\n",
    "            if candidate_state_maybe_none is None: continue\n",
    "            candidate = candidate_state_maybe_none.to(theta.device)\n",
    "\n",
    "            objective_value = torch.dot(theta, candidate)\n",
    "            if self.phi_network is not None:\n",
    "                phi_val = self.phi_network(candidate.unsqueeze(0) if candidate.dim()==1 else candidate)\n",
    "                objective_value += phi_val.squeeze()\n",
    "            \n",
    "            if objective_value > best_value:\n",
    "                best_value = objective_value\n",
    "                best_solution = candidate\n",
    "            self.solver_state['num_evaluations'] += 1\n",
    "        \n",
    "        self.solver_state['last_solution'] = best_solution.clone() if best_solution is not None else None\n",
    "        self.solver_state['last_objective_value'] = float(best_value)\n",
    "        self.solver_state['optimization_history'].append({\n",
    "            'solution': best_solution.clone().cpu().numpy() if best_solution is not None else None,\n",
    "            'value': float(best_value),\n",
    "            'search_space_size': len(search_space)\n",
    "        })\n",
    "        return best_solution\n",
    "    \n",
    "    def get_solver_state(self) -> Dict[str, Any]: return self.solver_state.copy()\n",
    "    def set_solver_parameters(self, params: Dict[str, Any]) -> None:\n",
    "        if 'reset_history' in params and params['reset_history']:\n",
    "            self.solver_state['optimization_history'] = []\n",
    "            self.solver_state['num_evaluations'] = 0\n",
    "\n",
    "\n",
    "class CorrectionRatioMCMC(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_space: DiscreteOutputSpace,\n",
    "                 config: MCMCConfig,\n",
    "                 phi_network: Optional[nn.Module] = None,\n",
    "                 exact_oracle: Optional[ExactOptimizationOracle] = None):\n",
    "        super().__init__()\n",
    "        self.output_space = output_space\n",
    "        self.config = config\n",
    "        self.phi_network = phi_network\n",
    "        self.exact_oracle = exact_oracle\n",
    "        self.temp_scheduler = self._create_temperature_scheduler()\n",
    "        self.persistent_states: Optional[List[Optional[torch.Tensor]]] = None\n",
    "        self.correction_ratios_log: List[float] = []\n",
    "        self.solver_diagnostics_log: List[Dict[str, Any]] = []\n",
    "        self.step_count = 0\n",
    "\n",
    "    def _create_temperature_scheduler(self) -> Callable[[int], float]:\n",
    "        if self.config.temperature_schedule == \"geometric\":\n",
    "            return TemperatureScheduler.geometric(self.config.initial_temp, self.config.decay_rate, self.config.final_temp)\n",
    "        elif self.config.temperature_schedule == \"linear\":\n",
    "            return TemperatureScheduler.linear(self.config.initial_temp, self.config.final_temp, self.config.chain_length)\n",
    "        else:\n",
    "            return TemperatureScheduler.constant(self.config.final_temp)\n",
    "\n",
    "    def phi_function(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        if self.phi_network is not None:\n",
    "            state_for_phi = state.unsqueeze(0) if state.dim() == self.output_space.dimension.bit_length() else state\n",
    "            if state_for_phi.dim() == 1: state_for_phi = state_for_phi.unsqueeze(0)\n",
    "\n",
    "            return self.phi_network(state_for_phi).squeeze()\n",
    "        return torch.tensor(0.0, device=state.device)\n",
    "\n",
    "    def compute_correction_ratio(self, current: torch.Tensor, proposal: torch.Tensor, theta: torch.Tensor, \n",
    "                                 strategy_name: str, strategy_params: Dict[str, Any]) -> float:\n",
    "        q_proposal_given_current = self.output_space.get_proposal_prob(current, proposal, strategy_name, **strategy_params)\n",
    "        q_current_given_proposal = self.output_space.get_proposal_prob(proposal, current, strategy_name, **strategy_params)\n",
    "\n",
    "        if q_proposal_given_current == 0: return 0.0\n",
    "        if q_current_given_proposal == 0: return float('inf')\n",
    "        \n",
    "        correction = q_current_given_proposal / q_proposal_given_current\n",
    "        return correction\n",
    "\n",
    "\n",
    "    def enhanced_acceptance_ratio(self, current: torch.Tensor, proposal: torch.Tensor, theta: torch.Tensor,\n",
    "                                temperature: float, strategy_name: str, strategy_params: Dict[str, Any]) -> float:\n",
    "        current_energy = torch.dot(theta, current) + self.phi_function(current)\n",
    "        proposal_energy = torch.dot(theta, proposal) + self.phi_function(proposal)\n",
    "        energy_diff = proposal_energy - current_energy\n",
    "        \n",
    "        correction_factor = self.compute_correction_ratio(current, proposal, theta, strategy_name, strategy_params)\n",
    "        self.correction_ratios_log.append(correction_factor)\n",
    "\n",
    "        if correction_factor < 0: correction_factor = 0.0\n",
    "        if temperature <= 1e-9:\n",
    "            return float('inf') if energy_diff <= 0 and correction_factor > 1e-9 else 0.0\n",
    "        \n",
    "        exp_term = torch.exp(energy_diff / temperature)\n",
    "        acceptance_term_pk = float(correction_factor * exp_term)\n",
    "        return max(0.0, acceptance_term_pk)\n",
    "\n",
    "    def large_neighborhood_search_step(self, current_state: torch.Tensor, theta: torch.Tensor, \n",
    "                                     neighborhood_size: int = 5) -> Optional[torch.Tensor]:\n",
    "        if self.exact_oracle is None:\n",
    "            available_strategies = self.output_space.get_available_neighborhood_strategies(current_state)\n",
    "            if not available_strategies: return current_state\n",
    "            chosen_strategy = random.choice(available_strategies)\n",
    "            s_params = {'radius': 1} if 'radius' in chosen_strategy else {'num_flips':1} if 'flip' in chosen_strategy else {}\n",
    "\n",
    "            neighbors = self.output_space.get_neighbors(current_state, chosen_strategy, **s_params)\n",
    "            return random.choice(neighbors) if neighbors else current_state\n",
    "\n",
    "        large_neighborhood: List[torch.Tensor] = []\n",
    "        strat_params = {'num_flips': neighborhood_size // 2, 'num_swaps': neighborhood_size // 2}\n",
    "        for strat_name in self.output_space.get_available_neighborhood_strategies(current_state):\n",
    "            large_neighborhood.extend(self.output_space.get_neighbors(current_state, strat_name, **strat_params))\n",
    "            if len(large_neighborhood) >= neighborhood_size: break\n",
    "        \n",
    "        while len(large_neighborhood) < neighborhood_size:\n",
    "            random_s = self.output_space.random_state()\n",
    "            if not any(torch.allclose(random_s, existing) for existing in large_neighborhood):\n",
    "                large_neighborhood.append(random_s)\n",
    "        \n",
    "        large_neighborhood = large_neighborhood[:min(len(large_neighborhood), neighborhood_size * 2)]\n",
    "\n",
    "        best_solution = self.exact_oracle.solve(theta, large_neighborhood)\n",
    "        if self.exact_oracle.solver_state:\n",
    "             self.solver_diagnostics_log.append(self.exact_oracle.get_solver_state())\n",
    "        return best_solution if best_solution is not None else current_state\n",
    "\n",
    "\n",
    "    def sample_chain_corrected(self, theta: torch.Tensor, chain_id: int = 0, \n",
    "                               target_state: Optional[torch.Tensor] = None,\n",
    "                               use_large_neighborhood_step_flag: bool = False\n",
    "                               ) -> Tuple[List[torch.Tensor], Dict[str, float]]:\n",
    "        if self.config.initialization_method == \"persistent\" and self.persistent_states is not None and \\\n",
    "           chain_id < len(self.persistent_states) and self.persistent_states[chain_id] is not None:\n",
    "            current_state = self.persistent_states[chain_id].clone().to(theta.device)\n",
    "        elif self.config.initialization_method == \"data_based\" and target_state is not None:\n",
    "            current_state = target_state.clone().to(theta.device)\n",
    "        else:\n",
    "            current_state = self.output_space.random_state().to(theta.device)\n",
    "\n",
    "        samples = []\n",
    "        acceptances = 0\n",
    "        total_steps_for_chain = self.config.chain_length + self.config.burn_in\n",
    "        \n",
    "        for step_idx in range(total_steps_for_chain):\n",
    "            temperature = self.temp_scheduler(step_idx)\n",
    "            proposal = None\n",
    "            chosen_strategy_name = \"unknown\"\n",
    "            strategy_params: Dict[str, Any] = {}\n",
    "\n",
    "            perform_lns_this_iteration = False\n",
    "            if use_large_neighborhood_step_flag and isinstance(self, LargeNeighborhoodSearchMCMC) and self.exact_oracle:\n",
    "                lns_freq = getattr(self, 'lns_frequency', 10) \n",
    "                if lns_freq > 0 and (step_idx + 1) % lns_freq == 0:\n",
    "                    perform_lns_this_iteration = True\n",
    "            \n",
    "            if perform_lns_this_iteration and isinstance(self, LargeNeighborhoodSearchMCMC):\n",
    "                lns_hood_size = getattr(self, 'lns_neighborhood_size', 5)\n",
    "                proposal = self.large_neighborhood_search_step(current_state, theta, lns_hood_size)\n",
    "                chosen_strategy_name = \"LNS\"\n",
    "                strategy_params = {'lns_generated': True}\n",
    "            else:\n",
    "                available_strategies = self.output_space.get_available_neighborhood_strategies(current_state)\n",
    "                if not available_strategies:\n",
    "                    if step_idx >= self.config.burn_in: samples.append(current_state.clone())\n",
    "                    continue\n",
    "                chosen_strategy_name = random.choice(available_strategies)\n",
    "                \n",
    "                if \"radius\" in chosen_strategy_name: strategy_params['radius'] = self.config.neighborhood_radius\n",
    "                elif \"flip\" in chosen_strategy_name: strategy_params['num_flips'] = 1\n",
    "                elif \"swap\" in chosen_strategy_name: strategy_params['num_swaps'] = 1\n",
    "                else: strategy_params['radius'] = self.config.neighborhood_radius\n",
    "\n",
    "                neighbors = self.output_space.get_neighbors(current_state, chosen_strategy_name, **strategy_params)\n",
    "                if not neighbors:\n",
    "                    if step_idx >= self.config.burn_in: samples.append(current_state.clone())\n",
    "                    continue\n",
    "                proposal = random.choice(neighbors)\n",
    "            \n",
    "            if proposal is None:\n",
    "                if step_idx >= self.config.burn_in: samples.append(current_state.clone())\n",
    "                continue\n",
    "            \n",
    "            proposal = proposal.to(theta.device)\n",
    "\n",
    "            acceptance_term_pk = self.enhanced_acceptance_ratio(current_state, proposal, theta[chain_id], temperature, chosen_strategy_name, strategy_params)\n",
    "            \n",
    "            if random.random() < min(1.0, acceptance_term_pk):\n",
    "                current_state = proposal\n",
    "                acceptances += 1\n",
    "            \n",
    "            if step_idx >= self.config.burn_in:\n",
    "                samples.append(current_state.clone())\n",
    "        \n",
    "        if self.persistent_states is None or len(self.persistent_states) != self.config.num_chains:\n",
    "             self.persistent_states = [None for _ in range(self.config.num_chains)]\n",
    "        self.persistent_states[chain_id] = current_state.clone()\n",
    "        \n",
    "        stats = {\n",
    "            'acceptance_rate': acceptances / total_steps_for_chain if total_steps_for_chain > 0 else 0.0,\n",
    "            'final_temperature': temperature,\n",
    "            'chain_length_collected': len(samples)\n",
    "        }\n",
    "        return samples, stats\n",
    "\n",
    "    def estimate_expectation_with_corrections(self, theta: torch.Tensor, target_state: Optional[torch.Tensor] = None,\n",
    "                                            use_large_neighborhood: bool = False\n",
    "                                            ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        all_samples: List[torch.Tensor] = []\n",
    "        all_stats: List[Dict[str, float]] = []\n",
    "        \n",
    "        if self.persistent_states is None or len(self.persistent_states) != self.config.num_chains:\n",
    "            self.persistent_states = [None for _ in range(self.config.num_chains)]\n",
    "\n",
    "        for chain_id in range(self.config.num_chains):\n",
    "            is_lns_sampler = isinstance(self, LargeNeighborhoodSearchMCMC)\n",
    "            samples, stats = self.sample_chain_corrected(\n",
    "                theta, chain_id, target_state,\n",
    "                use_large_neighborhood_step_flag=(use_large_neighborhood and is_lns_sampler)\n",
    "            )\n",
    "            all_samples.extend(samples)\n",
    "            all_stats.append(stats)\n",
    "        \n",
    "        if not all_samples:\n",
    "            zero_fallback = torch.zeros_like(theta) if theta is not None else torch.zeros(self.output_space.dimension, device=self.output_space.random_state().device)\n",
    "            warnings.warn(f\"No MCMC samples collected for theta. Returning zeros.\")\n",
    "            return zero_fallback, {'error': 'No samples collected', 'num_samples': 0, 'avg_acceptance_rate': 0.0, 'sample_entropy': 0.0}\n",
    "\n",
    "        expectation = torch.mean(torch.stack(all_samples).float(), dim=0)\n",
    "        \n",
    "        avg_acceptance_overall = np.mean([s['acceptance_rate'] for s in all_stats if 'acceptance_rate' in s]) if all_stats else 0.0\n",
    "        sample_entropy = compute_normalized_entropy(torch.stack(all_samples).detach().cpu()) if all_samples else 0.0\n",
    "        \n",
    "        combined_stats = {\n",
    "            'num_samples': len(all_samples),\n",
    "            'avg_acceptance_rate': float(avg_acceptance_overall),\n",
    "            'sample_entropy': float(sample_entropy),\n",
    "            'chain_stats': all_stats\n",
    "        }\n",
    "        return expectation, combined_stats\n",
    "    \n",
    "    def forward(self, theta: torch.Tensor, target: torch.Tensor, use_large_neighborhood: bool = False\n",
    "               ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        expectation, stats = self.estimate_expectation_with_corrections(theta, target_state=target, use_large_neighborhood=use_large_neighborhood)\n",
    "        return expectation, stats\n",
    "\n",
    "\n",
    "class LargeNeighborhoodSearchMCMC(CorrectionRatioMCMC):\n",
    "    def __init__(self, \n",
    "                 output_space: DiscreteOutputSpace,\n",
    "                 config: MCMCConfig,\n",
    "                 phi_network: Optional[nn.Module] = None,\n",
    "                 lns_frequency: int = 10,\n",
    "                 lns_neighborhood_size: int = 20):\n",
    "        exact_oracle = ExactOptimizationOracle(output_space, phi_network)\n",
    "        super().__init__(output_space, config, phi_network, exact_oracle)\n",
    "        self.lns_frequency = lns_frequency\n",
    "        self.lns_neighborhood_size = lns_neighborhood_size\n",
    "\n",
    "class EnhancedCTMFenchelYoungIntegration(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_space: DiscreteOutputSpace,\n",
    "                 mcmc_config: MCMCConfig,\n",
    "                 hidden_dim: int = 256,\n",
    "                 num_thought_steps: int = 5,\n",
    "                 use_large_neighborhood_search: bool = True,\n",
    "                 lns_frequency: int = 10,\n",
    "                 lns_neighborhood_size: int = 20):\n",
    "        super().__init__()\n",
    "        self.output_space_dim = output_space.dimension\n",
    "        \n",
    "        self.thought_network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.output_space_dim)\n",
    "        )\n",
    "        \n",
    "        self.phi_network = nn.Sequential(\n",
    "            nn.Linear(self.output_space_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        if use_large_neighborhood_search:\n",
    "            self.mcmc_sampler: Union[LargeNeighborhoodSearchMCMC, CorrectionRatioMCMC] = LargeNeighborhoodSearchMCMC(\n",
    "                output_space=output_space, config=mcmc_config, phi_network=self.phi_network,\n",
    "                lns_frequency=lns_frequency, lns_neighborhood_size=lns_neighborhood_size\n",
    "            )\n",
    "        else:\n",
    "            self.mcmc_sampler = CorrectionRatioMCMC(\n",
    "                output_space=output_space, config=mcmc_config, phi_network=self.phi_network\n",
    "            )\n",
    "        self.num_thought_steps = num_thought_steps\n",
    "\n",
    "    def forward(self, x: torch.Tensor, target_y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict[str, Any]]:\n",
    "        theta = self.thought_network(x)\n",
    "        \n",
    "        expectation_y, mcmc_stats = self.mcmc_sampler.estimate_expectation_with_corrections(\n",
    "            theta, target_state=target_y, \n",
    "            use_large_neighborhood=isinstance(self.mcmc_sampler, LargeNeighborhoodSearchMCMC)\n",
    "        )\n",
    "        \n",
    "        # The Fenchel-Young loss is typically <theta, E[y]> - <theta, y_target>\n",
    "        # The gradient w.r.t. theta is simply E[y] - y_target\n",
    "        loss = torch.sum(theta * (expectation_y.detach() - target_y))\n",
    "        \n",
    "        return loss, expectation_y, mcmc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa8fe1",
   "metadata": {},
   "source": [
    "## 8. Instantiation and Configuration\n",
    "This section defines necessary global configuration variables and then instantiates the core components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MAX_GRID_SIZE: (30, 30)\n",
      "Using NUM_ARC_SYMBOLS: 10\n",
      "Using ARC_INPUT_FLAT_DIM: 900\n",
      "Using MCMC_CONFIG_ARC: chains=3, length=20\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration Variables ---\n",
    "# These variables define the ARC environment and MCMC behavior.\n",
    "# NOTE: You must provide the paths to your ARC dataset directories.\n",
    "ARC_TRAIN_DIR = \"../data/training\" # <<< IMPORTANT: SET THIS PATH\n",
    "ARC_EVAL_DIR = \"../data/evaluation\"   # <<< IMPORTANT: SET THIS PATH\n",
    "\n",
    "MAX_GRID_SIZE = (30, 30)\n",
    "NUM_ARC_SYMBOLS = 10\n",
    "PADDING_VALUE = -1 # A value not in 0-9 to be ignored by the loss function\n",
    "MAX_DEMO_PAIRS = 5 # Max number of demonstration pairs to consider for context\n",
    "\n",
    "# Configuration for ARC-AGI-2 Training (shared constants)\n",
    "ARC_INPUT_FLAT_DIM = MAX_GRID_SIZE[0] * MAX_GRID_SIZE[1]\n",
    "\n",
    "# MCMC Configuration for ARC\n",
    "MCMC_OUTPUT_SPACE_DIM = ARC_INPUT_FLAT_DIM\n",
    "MCMC_CONFIG_ARC = MCMCConfig(\n",
    "    num_chains=3, \n",
    "    chain_length=20,\n",
    "    burn_in=5,\n",
    "    initial_temp=5.0,\n",
    "    final_temp=1.0,\n",
    "    temperature_schedule=\"geometric\",\n",
    "    decay_rate=0.95,\n",
    "    neighborhood_radius=1\n",
    ")\n",
    "ENABLE_CTM_MCMC_INTEGRATION_FOR_ARC = True\n",
    "\n",
    "print(f\"Using MAX_GRID_SIZE: {MAX_GRID_SIZE}\")\n",
    "print(f\"Using NUM_ARC_SYMBOLS: {NUM_ARC_SYMBOLS}\")\n",
    "print(f\"Using ARC_INPUT_FLAT_DIM: {ARC_INPUT_FLAT_DIM}\")\n",
    "print(f\"Using MCMC_CONFIG_ARC: chains={MCMC_CONFIG_ARC.num_chains}, length={MCMC_CONFIG_ARC.chain_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8467d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EnhancedCTMFenchelYoungIntegration module initialized.\n",
      "  Output space dimension: 900\n",
      "  MCMC sampler type: LargeNeighborhoodSearchMCMC\n",
      "    LNS Frequency: 5\n",
      "    LNS Neighborhood Size: 10\n",
      "\n",
      "ENHANCED_MCMC_AVAILABLE set to: True\n"
     ]
    }
   ],
   "source": [
    "# --- Instantiation ---\n",
    "arc_grid_output_space = ARCGridOutputSpace(\n",
    "    dimension=ARC_INPUT_FLAT_DIM,\n",
    "    grid_shape=MAX_GRID_SIZE,\n",
    "    num_symbols=NUM_ARC_SYMBOLS\n",
    ")\n",
    "\n",
    "ctm_encoder_output_dim = ARC_INPUT_FLAT_DIM \n",
    "\n",
    "enhanced_ctm_mcmc = None\n",
    "if ENABLE_CTM_MCMC_INTEGRATION_FOR_ARC:\n",
    "    enhanced_ctm_mcmc = EnhancedCTMFenchelYoungIntegration(\n",
    "        input_dim=ctm_encoder_output_dim, \n",
    "        output_space=arc_grid_output_space,\n",
    "        mcmc_config=MCMC_CONFIG_ARC,\n",
    "        use_large_neighborhood_search=True,\n",
    "        lns_frequency=5,\n",
    "        lns_neighborhood_size=10\n",
    "    )\n",
    "\n",
    "    print(f\"\\nEnhancedCTMFenchelYoungIntegration module initialized.\")\n",
    "    print(f\"  Output space dimension: {enhanced_ctm_mcmc.output_space_dim}\")\n",
    "    if isinstance(enhanced_ctm_mcmc.mcmc_sampler, LargeNeighborhoodSearchMCMC):\n",
    "        print(f\"  MCMC sampler type: LargeNeighborhoodSearchMCMC\")\n",
    "        print(f\"    LNS Frequency: {enhanced_ctm_mcmc.mcmc_sampler.lns_frequency}\")\n",
    "        print(f\"    LNS Neighborhood Size: {enhanced_ctm_mcmc.mcmc_sampler.lns_neighborhood_size}\")\n",
    "    else:\n",
    "        print(\"  MCMC sampler type: CorrectionRatioMCMC\")\n",
    "    ENHANCED_MCMC_AVAILABLE = True\n",
    "    print(f\"\\nENHANCED_MCMC_AVAILABLE set to: {ENHANCED_MCMC_AVAILABLE}\")\n",
    "else:\n",
    "    print(\"\\nMCMC Integration is disabled for ARC.\")\n",
    "    ENHANCED_MCMC_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073178b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC Output Head Dim: 9000\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "Initializing Configuration and Model for ARC with EnhancedCTMDiffusion\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedCTMConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\n-----------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Configuration and Model for ARC with EnhancedCTMDiffusion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m config_arc_diffusion \u001b[38;5;241m=\u001b[39m \u001b[43mEnhancedCTMConfig\u001b[49m(\n\u001b[1;32m    168\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m    169\u001b[0m     n_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m    170\u001b[0m     n_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, \n\u001b[1;32m    171\u001b[0m     max_sequence_length\u001b[38;5;241m=\u001b[39mMAX_SEQUENCE_LENGTH, \u001b[38;5;66;03m# From earlier in notebook (8192)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    173\u001b[0m     use_dynamic_entropy_patcher\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Enable new dynamic byte encoder\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     patch_embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m    175\u001b[0m     patch_encoder_cnn_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m    176\u001b[0m     entropy_patcher_threshold_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m     entropy_patcher_global_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m,\n\u001b[1;32m    178\u001b[0m     entropy_patcher_relative_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    179\u001b[0m     entropy_patcher_min_patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    180\u001b[0m     entropy_patcher_max_patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# Parameters for the learnable entropy model within LearnedBytePatcherEncoder\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     entropy_model_byte_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m    183\u001b[0m     entropy_model_embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m    184\u001b[0m     entropy_model_hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m    185\u001b[0m     entropy_model_num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    186\u001b[0m     entropy_model_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    187\u001b[0m     entropy_model_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;66;03m# Ensure auxiliary loss for entropy model contributes\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \n\u001b[1;32m    189\u001b[0m     ctm_input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, \u001b[38;5;66;03m# Input to CTM core, should match patch_embedding_dim if patcher is used directly\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     ctm_d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m    191\u001b[0m     ctm_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    192\u001b[0m     ctm_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m    193\u001b[0m     ctm_out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, \u001b[38;5;66;03m# Output from CTM core, used by external head\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     ctm_neuron_select_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbio_multi_objective\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \n\u001b[1;32m    196\u001b[0m     diffusion_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m    197\u001b[0m     ctm_diffusion_coupling_strength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m    198\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Using external head for ARC predictions\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     enable_enhanced_mcmc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Disable EnhancedCTMDiffusion's internal MCMC for this setup\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     ewc_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;66;03m# Disable EWC for this setup\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     output_audio_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# Not an audio task\u001b[39;00m\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ EnhancedCTMConfig for ARC (config_arc_diffusion) created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnhancedCTMDiffusion\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m EnhancedCTMDiffusion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EnhancedCTMConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# --- ARC Dataset and Dataloader Logic --- #All Module Paths should now be defined since the modules that are not on path are automatically added to path. \n",
    "\n",
    "# Note: The function `pad_grid` is called but not defined in the original source.\n",
    "# It is required for the NewCustomARCGridDataset to function correctly.\n",
    "# You must provide its definition. A placeholder is provided below.\n",
    "# --- Context: 2D Grid Padding (from original code) ---\n",
    "# This function handles padding at the 2D grid level, before serialization.\n",
    "def pad_grid(grid_list, max_dims, pad_value):\n",
    "    \"\"\"Pads a 2D grid to specified maximum dimensions.\"\"\"\n",
    "    grid_np = np.array(grid_list, dtype=np.int32)\n",
    "    padded_grid = np.full(max_dims, pad_value, dtype=np.int32)\n",
    "    h, w = grid_np.shape\n",
    "    padded_grid[:h, :w] = grid_np\n",
    "    return padded_grid\n",
    "\n",
    "# --- Fix: Byte Sequence Padding for the Model --- #\n",
    "# According to the model explanation, the key step is to pad the *serialized byte sequence*\n",
    "# to `config.max_sequence_length`. The function below implements this logic.\n",
    "\n",
    "# Define the model's expected input dimension from the configuration.\n",
    "MAX_SEQUENCE_LENGTH = 8192\n",
    "PADDING_BYTE_VALUE = 0\n",
    "\n",
    "def serialize_and_pad_grid(grid, max_len=MAX_SEQUENCE_LENGTH, pad_value=PADDING_BYTE_VALUE):\n",
    "    \"\"\"\n",
    "    Serializes a grid into a byte sequence and pads it to a fixed length.\n",
    "\n",
    "    This function implements the required padding logic for the LearnedBytePatcherEncoder.\n",
    "    It takes a grid, converts it to a flat byte sequence, and then pads or truncates\n",
    "    it to `max_sequence_length` (8192 bytes), ensuring a fixed-size input for the model.\n",
    "    \n",
    "    Args:\n",
    "        grid (list or np.ndarray): The input ARC grid.\n",
    "        max_len (int): The target length for the byte sequence, corresponding to\n",
    "                       `config.max_sequence_length`.\n",
    "        pad_value (int): The byte value to use for padding (0-255).\n",
    "\n",
    "    Returns:\n",
    "        bytes: The padded byte sequence of length `max_len`.\n",
    "    \"\"\"\n",
    "    # Convert the grid to a NumPy array of single bytes (uint8) and flatten it.\n",
    "    # ARC values (0-9) fit perfectly within a single byte.\n",
    "    flat_array = np.array(grid, dtype=np.uint8).flatten()\n",
    "\n",
    "    # Serialize the flattened array into a raw byte sequence.\n",
    "    byte_sequence = flat_array.tobytes()\n",
    "\n",
    "    # Calculate the number of padding bytes needed.\n",
    "    padding_len = max_len - len(byte_sequence)\n",
    "\n",
    "    if padding_len < 0:\n",
    "        # If the original sequence is too long, truncate it.\n",
    "        padded_sequence = byte_sequence[:max_len]\n",
    "    else:\n",
    "        # If the sequence is shorter, create padding and append it.\n",
    "        padding = bytes([pad_value] * padding_len)\n",
    "        padded_sequence = byte_sequence + padding\n",
    "        \n",
    "    return padded_sequence\n",
    "\n",
    "class NewCustomARCGridDataset(Dataset):\n",
    "    def __init__(self, data_dir, max_grid_size=MAX_GRID_SIZE, padding_value=PADDING_VALUE):\n",
    "        self.data_dir = data_dir\n",
    "        self.task_files = glob.glob(os.path.join(data_dir, \"*.json\"))\n",
    "        self.max_grid_size = max_grid_size\n",
    "        self.padding_value = padding_value\n",
    "        self.tasks = []\n",
    "        print(f\"NewCustomARCGridDataset: Looking for tasks in: {data_dir}\")\n",
    "        if not self.task_files:\n",
    "            print(f\"NewCustomARCGridDataset Warning: No JSON files found in {data_dir}. Dataset will be empty.\")\n",
    "        for task_file in self.task_files:\n",
    "            try:\n",
    "                with open(task_file, 'r') as f:\n",
    "                    self.tasks.append(json.load(f))\n",
    "            except Exception as e:\n",
    "                print(f\"NewCustomARCGridDataset Warning: Could not load or parse {task_file}: {e}\")\n",
    "        if not self.tasks:\n",
    "            print(f\"NewCustomARCGridDataset Warning: No tasks successfully loaded from {data_dir}.\")\n",
    "        else:\n",
    "            print(f\"NewCustomARCGridDataset: Loaded {len(self.tasks)} ARC tasks from {data_dir}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        task_data = self.tasks[idx]\n",
    "        processed_task = {'train': [], 'test': [], 'id': os.path.basename(self.task_files[idx]) if idx < len(self.task_files) else 'unknown_task'}\n",
    "\n",
    "        for pair_type in ['train', 'test']:\n",
    "            for item in task_data.get(pair_type, []):\n",
    "                input_grid_list = item.get('input', [])\n",
    "                output_grid_list = item.get('output', [])\n",
    "                \n",
    "                original_input_dims = (len(input_grid_list), len(input_grid_list[0]) if input_grid_list and input_grid_list[0] else (0,0))\n",
    "                original_output_dims = (len(output_grid_list), len(output_grid_list[0]) if output_grid_list and output_grid_list[0] else (0,0))\n",
    "\n",
    "                padded_input_np = pad_grid(input_grid_list, self.max_grid_size, self.padding_value)\n",
    "                padded_output_np = pad_grid(output_grid_list, self.max_grid_size, self.padding_value)\n",
    "                \n",
    "                processed_task[pair_type].append({\n",
    "                    'input': torch.from_numpy(padded_input_np).long(),\n",
    "                    'output': torch.from_numpy(padded_output_np).long(),\n",
    "                    'original_input_dims': original_input_dims,\n",
    "                    'original_output_dims': original_output_dims\n",
    "                })\n",
    "        return processed_task\n",
    "\n",
    "def collate_fn_new_custom_arc(batch_of_tasks):\n",
    "    input_byte_sequences_list = []\n",
    "    target_byte_sequences_for_diffusion_list = []\n",
    "    original_target_grids_for_ce_loss_list = []\n",
    "\n",
    "    for task in batch_of_tasks:\n",
    "        if not isinstance(task, dict):\n",
    "            continue\n",
    "\n",
    "        # Process 'train' pairs from the task\n",
    "        for train_pair in task.get('train', []):\n",
    "            if not isinstance(train_pair, dict) or 'input' not in train_pair or 'output' not in train_pair:\n",
    "                continue\n",
    "\n",
    "            # train_pair['input'] and train_pair['output'] are already padded 2D LongTensors from NewCustomARCGridDataset\n",
    "            input_grid_np = train_pair['input'].numpy() # Convert to numpy for serialize_and_pad_grid\n",
    "            target_grid_np = train_pair['output'].numpy()\n",
    "\n",
    "            # 1. Create input_byte_sequences (uint8)\n",
    "            input_bytes = serialize_and_pad_grid(input_grid_np, max_len=MAX_SEQUENCE_LENGTH, pad_value=PADDING_BYTE_VALUE)\n",
    "            input_byte_sequences_list.append(torch.tensor(list(input_bytes), dtype=torch.uint8))\n",
    "\n",
    "            # 2. Create target_byte_sequences_for_diffusion (uint8)\n",
    "            target_bytes_for_diffusion = serialize_and_pad_grid(target_grid_np, max_len=MAX_SEQUENCE_LENGTH, pad_value=PADDING_BYTE_VALUE)\n",
    "            target_byte_sequences_for_diffusion_list.append(torch.tensor(list(target_bytes_for_diffusion), dtype=torch.uint8))\n",
    "\n",
    "            # 3. Keep original_target_grids_for_ce_loss (long tensor, flattened)\n",
    "            original_target_grids_for_ce_loss_list.append(train_pair['output'].view(-1)) # Flattened LongTensor\n",
    "            \n",
    "    if not input_byte_sequences_list:\n",
    "        return {\n",
    "            'input_byte_sequences': torch.empty(0, MAX_SEQUENCE_LENGTH, dtype=torch.uint8),\n",
    "            'target_byte_sequences_for_diffusion': torch.empty(0, MAX_SEQUENCE_LENGTH, dtype=torch.uint8),\n",
    "            'original_target_grids_for_ce_loss': torch.empty(0, ARC_INPUT_FLAT_DIM, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    # Stack all collected tensors\n",
    "    final_input_byte_sequences = torch.stack(input_byte_sequences_list)\n",
    "    final_target_byte_sequences_for_diffusion = torch.stack(target_byte_sequences_for_diffusion_list)\n",
    "    final_original_target_grids_for_ce_loss = torch.stack(original_target_grids_for_ce_loss_list)\n",
    "    \n",
    "    return {\n",
    "        'input_byte_sequences': final_input_byte_sequences,\n",
    "        'target_byte_sequences_for_diffusion': final_target_byte_sequences_for_diffusion,\n",
    "        'original_target_grids_for_ce_loss': final_original_target_grids_for_ce_loss,\n",
    "    }\n",
    "\n",
    "# --- ARC Training Setup ---\n",
    "ARC_OUTPUT_HEAD_DIM = ARC_INPUT_FLAT_DIM * NUM_ARC_SYMBOLS\n",
    "ARC_TASK_ID = 3\n",
    "print(f\"ARC Output Head Dim: {ARC_OUTPUT_HEAD_DIM}\")\n",
    "\n",
    "ctm_model_arc, arc_output_head, optimizer_arc, ctm_mcmc_integration_arc, accelerator_arc = None, None, None, None, None\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------\")\n",
    "print(\"Initializing Configuration and Model for ARC with EnhancedCTMDiffusion\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "'''\n",
    "You do not need to add any of the variables again from the ctm_Diffusion_NEWNEW.py file to your config_arc_diffusion in the Arc_AGI_2_Final.ipynb file. All the parameters you listed are already explicitly defined when config_arc_diffusion is created (between lines 2200 and 2378 approximately).\n",
    "\n",
    "The EnhancedCTMConfig class in ctm_Diffusion_NEWNEW.py provides default values for its fields. When you create an instance like config_arc_diffusion, any parameters you explicitly set will override these defaults. Since all the parameters in your list are already set in your notebook, those are the values that will be used for training.\n",
    "\n",
    "For example:\n",
    "\n",
    "attention_type is set to \"subquadratic\" on line 2260.\n",
    "positional_embedding_type is set to 'multi-learnable-fourier' on line 2276.\n",
    "enable_pipeline_parallelism is set to True on line 2288.\n",
    "And so on for all the other parameters you mentioned.\n",
    "If you wish to change any of these settings, you should modify their values directly in the existing config_arc_diffusion definition within your Arc_AGI_2_Final.ipynb file.\n",
    "'''\n",
    "\n",
    "# Define EnhancedCTMConfig for ARC with EnhancedCTMDiffusion\n",
    "# Assuming EnhancedCTMConfig is a defined class and MAX_SEQUENCE_LENGTH is a defined variable\n",
    "# For example:\n",
    "# from your_model_library import EnhancedCTMConfig\n",
    "# MAX_SEQUENCE_LENGTH = 8192\n",
    "\n",
    "# Define EnhancedCTMConfig for ARC with EnhancedCTMDiffusion\n",
    "config_arc_diffusion = EnhancedCTMConfig(\n",
    "    d_model=512,\n",
    "    #inferred_task_latent_dim=64, # This line remains commented out\n",
    "    n_heads=8,\n",
    "    n_layers=24, \n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    dropout=0.1,\n",
    "    use_dynamic_entropy_patcher=True,\n",
    "    patch_embedding_dim=256,\n",
    "    patch_grid_width=16,\n",
    "    patch_encoder_cnn_channels=64,\n",
    "    entropy_patcher_threshold_type=\"global\",\n",
    "    entropy_patcher_global_threshold=0.75,\n",
    "    entropy_patcher_relative_threshold=0.1,\n",
    "    entropy_patcher_min_patch_size=4,\n",
    "    entropy_patcher_max_patch_size=128,\n",
    "    # Parameters for the learnable entropy model within LearnedBytePatcherEncoder\n",
    "    entropy_model_byte_vocab_size=256,\n",
    "    entropy_model_embedding_dim=64,\n",
    "    entropy_model_hidden_dim=128,\n",
    "    entropy_model_num_layers=1,\n",
    "    entropy_model_dropout=0.1,\n",
    "    entropy_model_loss_weight=0.1,\n",
    "    \n",
    "    ctm_input_dim=256,\n",
    "    ctm_d_model=512,\n",
    "    ctm_iterations=5,\n",
    "    ctm_heads=8,\n",
    "    ctm_out_dims=512,\n",
    "    ctm_neuron_select_type='bio_multi_objective',\n",
    "    \n",
    "    # Attention Mechanism Type\n",
    "    attention_type=\"subquadratic\",  # Options: \"standard\", \"binary_sparse\", \"subquadratic\"\n",
    "    \n",
    "    # Subquadratic Attention Parameters\n",
    "    subquadratic_attn_epsilon=1e-6,\n",
    "    subquadratic_attn_poly_degree=5,\n",
    "    attention_qkv_bias=True, # Corrected capitalization\n",
    "    \n",
    "    # Positional Embedding Parameters\n",
    "    positional_embedding_type='multi-learnable-fourier',\n",
    "    positional_embedding_dim=None,\n",
    "    reshape_patch_sequence_to_grid=True,\n",
    "    #patch_grid_width=None, #Already defined in the byte patch section of this config. \n",
    "\n",
    "    # Pipeline Parallelism Parameters\n",
    "    enable_pipeline_parallelism=True,\n",
    "    pipeline_stages=4,\n",
    "    pipeline_overlap_ratio=0.7,\n",
    "    \n",
    "    # Adaptive Batch Sizing Parameters\n",
    "    enable_adaptive_batching=True,\n",
    "    initial_batch_size=32,\n",
    "    min_batch_size=8,\n",
    "    max_batch_size=256,\n",
    "    batch_adaptation_frequency=100,\n",
    "    memory_threshold_high=0.85,\n",
    "    memory_threshold_low=0.6,\n",
    "    \n",
    "    # Smart Data Sampling Parameters\n",
    "    enable_smart_sampling=True,\n",
    "    sample_importance_weight=0.6,\n",
    "    sample_diversity_weight=0.4,\n",
    "    initial_sample_ratio=0.3,\n",
    "    complexity_analysis_enabled=True,\n",
    "    \n",
    "    # Multi-input/output parameters\n",
    "    num_inputs=1,\n",
    "    num_outputs=1,\n",
    "    output_dims=[64],  # Directly pass the list value\n",
    "    \n",
    "    # Self-supervised learning\n",
    "    ssl_dim=128,\n",
    "    ssl_weight=0.1,\n",
    "    ssl_temperature=0.07,\n",
    "    ssl_noise_std=0.1,\n",
    "    \n",
    "    # Spatiotemporal Processing\n",
    "    use_spatial=True,\n",
    "    \n",
    "    # WINA Attention\n",
    "    use_wina_attention=True,\n",
    "    \n",
    "    # Multi-task Learning Parameters\n",
    "    max_tasks=50,\n",
    "    diffusion_steps=1000,\n",
    "    ctm_diffusion_coupling_strength=0.8,\n",
    "    vocab_size=None,\n",
    "    #enable_enhanced_mcmc=False, #ONLY USE THE ARC_AGI NOTEBOOK VERSION AND NOT THE ONE IMPORTED FROM THE DIFFUSION_NEWNEW file (This needs to be false). This flie cannot use this variable.\n",
    "    #mcmc_config=MCMC_CONFIG_ARC, #I don't think this is needed. \n",
    "    ewc_lambda=0.0,\n",
    "    output_audio_bytes=False\n",
    ")\n",
    "\n",
    "print(\"âœ“ EnhancedCTMConfig for ARC (config_arc_diffusion) created.\")\n",
    "\n",
    "if 'enhanced_ctm_mcmc' not in globals():\n",
    "    print(\"Warning: 'enhanced_ctm_mcmc' not found in globals. Defaulting to None. Ensure the cell defining it (approx. lines 1820-1866) was run successfully.\")\n",
    "    enhanced_ctm_mcmc = None\n",
    "    \n",
    "if 'EnhancedCTMDiffusion' in globals() and EnhancedCTMDiffusion is not None:\n",
    "    ctm_model_arc = EnhancedCTMDiffusion(config=config_arc_diffusion).to(device)\n",
    "    print(\"âœ“ EnhancedCTMDiffusion model for ARC (ctm_model_arc) initialized.\")\n",
    "\n",
    "    # The external ARC output head will take features from the CTM core part of EnhancedCTMDiffusion\n",
    "    arc_output_head_input_dim = config_arc_diffusion.output_dims[0]\n",
    "    arc_output_head = nn.Linear(arc_output_head_input_dim, ARC_OUTPUT_HEAD_DIM).to(device)\n",
    "    print(f\"âœ“ ARC Output Head initialized (input_dim: {arc_output_head_input_dim}, output_dim: {ARC_OUTPUT_HEAD_DIM}).\")\n",
    "\n",
    "    # Handle external MCMC integration if enabled\n",
    "    if ENABLE_CTM_MCMC_INTEGRATION_FOR_ARC and enhanced_ctm_mcmc:\n",
    "        # Ensure the external MCMC module's input_dim matches the new CTM's output\n",
    "        if enhanced_ctm_mcmc.thought_network[0].in_features != config_arc_diffusion.output_dims[0]:\n",
    "            print(f\"Re-initializing external enhanced_ctm_mcmc for new input_dim {config_arc_diffusion.output_dims[0]}\")\n",
    "            enhanced_ctm_mcmc = EnhancedCTMFenchelYoungIntegration(\n",
    "                input_dim=config_arc_diffusion.output_dims[0], # Use output dim of CTM core\n",
    "                output_space=arc_grid_output_space,\n",
    "                mcmc_config=MCMC_CONFIG_ARC,\n",
    "                use_large_neighborhood_search=True,\n",
    "                lns_frequency=5,\n",
    "                lns_neighborhood_size=10\n",
    "            )\n",
    "        ctm_mcmc_integration_arc = enhanced_ctm_mcmc.to(device) if enhanced_ctm_mcmc else None\n",
    "        print(f\"âœ“ External MCMC Integration for ARC is {'enabled' if ctm_mcmc_integration_arc else 'FAILED to enable'}.\")\n",
    "    \n",
    "    arc_trainable_params = list(ctm_model_arc.parameters()) # EnhancedCTMDiffusion parameters\n",
    "    if arc_output_head: arc_trainable_params.extend(list(arc_output_head.parameters()))\n",
    "    if ctm_mcmc_integration_arc:\n",
    "        arc_trainable_params.extend(list(ctm_mcmc_integration_arc.parameters()))\n",
    "\n",
    "    optimizer_arc = optim.AdamW([p for p in arc_trainable_params if p.requires_grad], lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    \n",
    "    if ACCELERATE_AVAILABLE:\n",
    "        accelerator_arc = Accelerator()\n",
    "        models_to_prepare = [ctm_model_arc] # Start with the main model\n",
    "        if arc_output_head: models_to_prepare.append(arc_output_head)\n",
    "        if ctm_mcmc_integration_arc: models_to_prepare.append(ctm_mcmc_integration_arc)\n",
    "        \n",
    "        prepared_components = accelerator_arc.prepare(*models_to_prepare, optimizer_arc)\n",
    "        \n",
    "        optimizer_arc = prepared_components[-1] # Last element is the optimizer\n",
    "        prepared_models_tuple = prepared_components[:-1] # All other elements are models\n",
    "\n",
    "        ctm_model_arc = prepared_models_tuple[0]\n",
    "        model_idx = 1\n",
    "        if arc_output_head:\n",
    "            arc_output_head = prepared_models_tuple[model_idx]\n",
    "            model_idx +=1\n",
    "        if ctm_mcmc_integration_arc:\n",
    "            ctm_mcmc_integration_arc = prepared_models_tuple[model_idx]\n",
    "        print(\"âœ“ ARC models (EnhancedCTMDiffusion) and optimizer prepared with Accelerate.\")\n",
    "else:\n",
    "    print(\"âš ï¸ EnhancedCTMDiffusion model or its config for ARC-AGI-2 could not be initialized. Check imports.\")\n",
    "\n",
    "CHECKPOINT_DIR_ARC = os.path.join(CHECKPOINT_DIR, \"ctm_arc_agi_2_enhanced_diffusion\") # New checkpoint dir\n",
    "os.makedirs(CHECKPOINT_DIR_ARC, exist_ok=True)\n",
    "print(f\"ARC Checkpoints will be saved to: {CHECKPOINT_DIR_ARC}\")\n",
    "\n",
    "NUM_EPOCHS_ARC = 20\n",
    "ARC_BATCH_SIZE = 8\n",
    "\n",
    "arc_train_dataset = NewCustomARCGridDataset(ARC_TRAIN_DIR)\n",
    "arc_eval_dataset = NewCustomARCGridDataset(ARC_EVAL_DIR)\n",
    "\n",
    "arc_train_loader, arc_eval_loader = None, None\n",
    "if arc_train_dataset and len(arc_train_dataset) > 0:\n",
    "    arc_train_loader = DataLoader(\n",
    "        arc_train_dataset, batch_size=ARC_BATCH_SIZE, shuffle=True,\n",
    "        collate_fn=collate_fn_new_custom_arc, **OPTIMIZED_DATALOADER_CONFIG\n",
    "    )\n",
    "    if accelerator_arc: arc_train_loader = accelerator_arc.prepare(arc_train_loader)\n",
    "    print(f\"âœ“ ARC Training DataLoader initialized with {len(arc_train_dataset)} tasks.\")\n",
    "else:\n",
    "    print(\"âš ï¸ ARC Training DataLoader could not be initialized.\")\n",
    "\n",
    "if arc_eval_dataset and len(arc_eval_dataset) > 0:\n",
    "    arc_eval_loader = DataLoader(\n",
    "        arc_eval_dataset, batch_size=1, shuffle=False,\n",
    "        collate_fn=collate_fn_new_custom_arc, **OPTIMIZED_DATALOADER_CONFIG\n",
    "    )\n",
    "    if accelerator_arc: arc_eval_loader = accelerator_arc.prepare(arc_eval_loader)\n",
    "    print(f\"âœ“ ARC Evaluation DataLoader initialized with {len(arc_eval_dataset)} tasks.\")\n",
    "else:\n",
    "    print(\"âš ï¸ ARC Evaluation DataLoader could not be initialized.\")\n",
    "\n",
    "arc_criterion = nn.CrossEntropyLoss(ignore_index=PADDING_VALUE)\n",
    "print(\"\\nâœ“ ARC-AGI-2 Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ARC-AGI-2 Training Loop ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸš€ STARTING PHASE 4: ARC-AGI-2 Training\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS_ARC}, Batch Size: {ARC_BATCH_SIZE}, Task ID: {ARC_TASK_ID}\")\n",
    "print(f\"   Device: {device if not accelerator_arc else accelerator_arc.device}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if not all([ctm_model_arc, arc_output_head, optimizer_arc, arc_train_loader, arc_criterion]):\n",
    "    print(\"âš ï¸ Skipping ARC-AGI-2 training due to missing components.\")\n",
    "else:\n",
    "    for epoch in range(NUM_EPOCHS_ARC):\n",
    "        ctm_model_arc.train()\n",
    "        arc_output_head.train()\n",
    "        if ctm_mcmc_integration_arc: ctm_mcmc_integration_arc.train()\n",
    "\n",
    "        total_arc_loss = 0\n",
    "        processed_batches = 0\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(arc_train_loader):\n",
    "            if not batch_data or batch_data['input_byte_sequences'].numel() == 0:\n",
    "                print(f\"Skipping empty batch {batch_idx}\")\n",
    "                continue\n",
    "\n",
    "            # Get data from the updated collate_fn\n",
    "            input_bytes = batch_data['input_byte_sequences'].to(device if not accelerator_arc else accelerator_arc.device)\n",
    "            target_bytes_for_diffusion = batch_data['target_byte_sequences_for_diffusion'].to(device if not accelerator_arc else accelerator_arc.device)\n",
    "            original_target_grids_for_ce = batch_data['original_target_grids_for_ce_loss'].to(device if not accelerator_arc else accelerator_arc.device)\n",
    "\n",
    "            current_batch_size = input_bytes.size(0)\n",
    "\n",
    "            optimizer_arc.zero_grad()\n",
    "\n",
    "            with autocast(enabled=USE_MIXED_PRECISION, dtype=autocast_dtype) if not accelerator_arc else accelerator_arc.autocast():\n",
    "                # Forward pass through EnhancedCTMDiffusion\n",
    "                # The model internally handles patching, CTM core, diffusion (if target provided), and entropy aux loss.\n",
    "                model_output_dict = ctm_model_arc(\n",
    "                    byte_sequence=input_bytes,\n",
    "                    target_diffusion_output=target_bytes_for_diffusion, # Provide target for diffusion loss component\n",
    "                    mode='ctm_controlled_diffusion', # Ensure diffusion part is active for loss calculation\n",
    "                    timestep=torch.randint(0, config_arc_diffusion.diffusion_steps, (current_batch_size,), device=input_bytes.device).long(), # Random timesteps for diffusion training\n",
    "                    target_mcmc_output=None, # Internal MCMC is disabled in config_arc_diffusion\n",
    "                    task_name=\"ARC_AGI_2\", # Optional task name\n",
    "                    current_epoch=epoch # Pass current epoch\n",
    "                )\n",
    "\n",
    "                # Loss from EnhancedCTMDiffusion (includes entropy aux loss, diffusion loss, etc.)\n",
    "                enhanced_ctm_loss = model_output_dict.get('total_loss', torch.tensor(0.0, device=input_bytes.device))\n",
    "                loss = enhanced_ctm_loss\n",
    "\n",
    "                # Get CTM core output for the external ARC head\n",
    "                ctm_core_output_data = model_output_dict.get('ctm_core_data')\n",
    "                ctm_backbone_output = None\n",
    "                if ctm_core_output_data and 'final_sync_out' in ctm_core_output_data:\n",
    "                    ctm_backbone_output = ctm_core_output_data['final_sync_out']\n",
    "                elif ctm_core_output_data and 'ctm_latent_representation' in ctm_core_output_data: # Fallback key\n",
    "                    ctm_backbone_output = ctm_core_output_data['ctm_latent_representation']\n",
    "                else:\n",
    "                    print(\"Warning: CTM core output ('final_sync_out' or 'ctm_latent_representation') not found. Using zeros for ARC head input.\")\n",
    "                    ctm_backbone_output = torch.zeros(current_batch_size, config_arc_diffusion.ctm_out_dims, device=input_bytes.device)\n",
    "                \n",
    "                # External ARC Output Head for CrossEntropy loss on original grid prediction\n",
    "                if arc_output_head and ctm_backbone_output is not None:\n",
    "                    if ctm_backbone_output.ndim > 2 and ctm_backbone_output.shape[1] > 0:\n",
    "                         ctm_features_for_head = ctm_backbone_output.mean(dim=1)\n",
    "                    else:\n",
    "                         ctm_features_for_head = ctm_backbone_output\n",
    "                    \n",
    "                    predicted_logits = arc_output_head(ctm_features_for_head)\n",
    "                    predicted_logits_reshaped = predicted_logits.view(current_batch_size * ARC_INPUT_FLAT_DIM, NUM_ARC_SYMBOLS)\n",
    "                    target_grids_reshaped = original_target_grids_for_ce.view(current_batch_size * ARC_INPUT_FLAT_DIM)\n",
    "                    ce_loss = arc_criterion(predicted_logits_reshaped, target_grids_reshaped)\n",
    "                    loss += ce_loss # Add CE loss to the total loss\n",
    "\n",
    "                # External MCMC Integration (if enabled)\n",
    "                if ctm_mcmc_integration_arc and ctm_backbone_output is not None:\n",
    "                    target_grids_for_mcmc = (original_target_grids_for_ce > 0).float()\n",
    "                    mcmc_input_features = ctm_backbone_output.detach()\n",
    "                    if mcmc_input_features.ndim > 2 and mcmc_input_features.shape[1] > 0:\n",
    "                        mcmc_input_features = mcmc_input_features.mean(dim=1)\n",
    "\n",
    "                    mcmc_loss_val, _, _ = ctm_mcmc_integration_arc(\n",
    "                        x=mcmc_input_features,\n",
    "                        target_y=target_grids_for_mcmc \n",
    "                    )\n",
    "                    loss += mcmc_loss_val\n",
    "\n",
    "            if scaler: # Mixed precision (manual, without Accelerate)\n",
    "                scaler.scale(loss).backward()\n",
    "                if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    scaler.unscale_(optimizer_arc)\n",
    "                    torch.nn.utils.clip_grad_norm_(ctm_model_arc.parameters(), MAX_GRAD_NORM)\n",
    "                    scaler.step(optimizer_arc)\n",
    "                    scaler.update()\n",
    "                    optimizer_arc.zero_grad()\n",
    "            elif accelerator_arc: # Using Hugging Face Accelerate\n",
    "                 accelerator_arc.backward(loss)\n",
    "                 if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    optimizer_arc.step()\n",
    "                    optimizer_arc.zero_grad()\n",
    "            else: # Standard training\n",
    "                loss.backward()\n",
    "                if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(ctm_model_arc.parameters(), MAX_GRAD_NORM)\n",
    "                    optimizer_arc.step()\n",
    "                    optimizer_arc.zero_grad()\n",
    "            \n",
    "            total_arc_loss += loss.item()\n",
    "            processed_batches += 1\n",
    "\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f\"  Epoch [{epoch+1}/{NUM_EPOCHS_ARC}], Batch [{batch_idx+1}/{len(arc_train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        avg_epoch_loss = total_arc_loss / processed_batches if processed_batches > 0 else 0\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS_ARC}] completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        if SAFETENSORS_AVAILABLE and CHECKPOINT_DIR_ARC:\n",
    "            model_to_save_ctm = accelerator_arc.unwrap_model(ctm_model_arc) if accelerator_arc else ctm_model_arc\n",
    "            model_to_save_head = accelerator_arc.unwrap_model(arc_output_head) if accelerator_arc else arc_output_head\n",
    "            \n",
    "            save_model(model_to_save_ctm, os.path.join(CHECKPOINT_DIR_ARC, f\"ctm_model_arc_epoch_{epoch+1}.safetensors\"))\n",
    "            save_model(model_to_save_head, os.path.join(CHECKPOINT_DIR_ARC, f\"arc_output_head_epoch_{epoch+1}.safetensors\"))\n",
    "            torch.save(optimizer_arc.state_dict(), os.path.join(CHECKPOINT_DIR_ARC, f\"optimizer_arc_epoch_{epoch+1}.pt\"))\n",
    "            print(f\"  âœ“ Checkpoint saved for epoch {epoch+1} to {CHECKPOINT_DIR_ARC}\")\n",
    "\n",
    "    print(\"\\nðŸŽ‰ ARC-AGI-2 Training Phase Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ARC-AGI-2 Evaluation\n",
    "\n",
    "import traceback\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸ”¬ STARTING ARC-AGI-2 Evaluation\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if not all([ctm_model_arc is not None, arc_output_head is not None, arc_eval_loader is not None]):\n",
    "    print(\"âš ï¸ Skipping ARC-AGI-2 evaluation due to missing components.\")\n",
    "else:\n",
    "    latest_epoch = NUM_EPOCHS_ARC\n",
    "    ctm_checkpoint_path_eval = os.path.join(CHECKPOINT_DIR_ARC, f\"ctm_model_arc_epoch_{latest_epoch}.safetensors\")\n",
    "    head_checkpoint_path_eval = os.path.join(CHECKPOINT_DIR_ARC, f\"arc_output_head_epoch_{latest_epoch}.safetensors\")\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(ctm_checkpoint_path_eval) and callable(load_model):\n",
    "            unwrapped_ctm_model = accelerator_arc.unwrap_model(ctm_model_arc) if accelerator_arc else ctm_model_arc\n",
    "            load_model(unwrapped_ctm_model, ctm_checkpoint_path_eval, device=device if not accelerator_arc else accelerator_arc.device)\n",
    "            print(f\"âœ“ Loaded CTM checkpoint from epoch {latest_epoch}.\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ CTM Checkpoint not found. Evaluating with current model state.\")\n",
    "\n",
    "        if os.path.exists(head_checkpoint_path_eval) and callable(load_model):\n",
    "            unwrapped_head_model = accelerator_arc.unwrap_model(arc_output_head) if accelerator_arc else arc_output_head\n",
    "            load_model(unwrapped_head_model, head_checkpoint_path_eval, device=device if not accelerator_arc else accelerator_arc.device)\n",
    "            print(f\"âœ“ Loaded ARC Output Head checkpoint from epoch {latest_epoch}.\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ARC Output Head Checkpoint not found. Evaluating with current model state.\")\n",
    "        \n",
    "        ctm_model_arc.eval()\n",
    "        arc_output_head.eval()\n",
    "        if ctm_mcmc_integration_arc: ctm_mcmc_integration_arc.eval()\n",
    "\n",
    "        total_tasks = 0\n",
    "        solved_tasks = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for task_idx, task_batch in enumerate(arc_eval_loader):\n",
    "                if not task_batch: continue\n",
    "                \n",
    "                current_task_data = task_batch # Dataloader batch_size=1, so task_batch is the task dict\n",
    "                \n",
    "                total_tasks += 1\n",
    "                task_solved_overall = True\n",
    "\n",
    "                if 'test' not in current_task_data or not current_task_data['test']:\n",
    "                    print(f\"Task {task_idx + 1} ({current_task_data.get('id', 'N/A')}): No test cases found. Skipping.\")\n",
    "                    task_solved_overall = False\n",
    "                    continue\n",
    "\n",
    "                for test_pair_idx, test_pair in enumerate(current_task_data['test']):\n",
    "                    # Input for evaluation is a single grid, needs to be converted to byte sequence\n",
    "                    input_grid_np_eval = test_pair['input'].numpy() # Get numpy array from tensor\n",
    "                    input_bytes_eval_single = serialize_and_pad_grid(input_grid_np_eval, max_len=MAX_SEQUENCE_LENGTH, pad_value=PADDING_BYTE_VALUE)\n",
    "                    input_bytes_eval = torch.tensor(list(input_bytes_eval_single), dtype=torch.uint8).unsqueeze(0).to(device if not accelerator_arc else accelerator_arc.device)\n",
    "\n",
    "                    target_grid_np = test_pair['output'].cpu().numpy()\n",
    "                    original_dims = test_pair['original_output_dims']\n",
    "\n",
    "                    test_input_solved = False\n",
    "                    for trial in range(3): # ARC rules allow 3 trials\n",
    "                        # Forward pass with EnhancedCTMDiffusion using CTM-controlled diffusion for generation\n",
    "                        # Assuming timestep 0 is appropriate for one-step or final-step generation\n",
    "                        current_batch_size_eval = input_bytes_eval.size(0) # Should be 1 for evaluation\n",
    "                        eval_timestep = torch.zeros(current_batch_size_eval, device=input_bytes_eval.device).long()\n",
    "\n",
    "                        eval_model_output_dict = ctm_model_arc(\n",
    "                            byte_sequence=input_bytes_eval,\n",
    "                            mode='ctm_controlled_diffusion', # Use CTM-controlled diffusion\n",
    "                            target_diffusion_output=None,   # No target during generation\n",
    "                            timestep=eval_timestep,\n",
    "                            task_name=\"ARC_AGI_2_EVAL_DIFFUSION\"\n",
    "                        )\n",
    "                        \n",
    "                        # ASSUMPTION: The generated output is a byte sequence under the key 'diffusion_output_pred'\n",
    "                        # The shape is expected to be (batch_size, MAX_SEQUENCE_LENGTH)\n",
    "                        predicted_byte_sequence = eval_model_output_dict.get('diffusion_output_pred') \n",
    "                        \n",
    "                        if predicted_byte_sequence is None:\n",
    "                            print(\"Warning: Key 'diffusion_output_pred' not found in model output. Trying 'generated_output'.\")\n",
    "                            predicted_byte_sequence = eval_model_output_dict.get('generated_output') # Common alternative\n",
    "                        \n",
    "                        if predicted_byte_sequence is None:\n",
    "                            print(\"Warning: Generated output key not found. Using zeros as prediction.\")\n",
    "                            # Fallback: create a zero tensor of the expected grid size if generation fails to be found\n",
    "                            preds_grid = np.zeros(MAX_GRID_SIZE, dtype=int)\n",
    "                        else:\n",
    "                            # Ensure the sequence has the correct batch dimension (should be 1)\n",
    "                            if predicted_byte_sequence.ndim == 1 and current_batch_size_eval == 1:\n",
    "                                predicted_byte_sequence = predicted_byte_sequence.unsqueeze(0)\n",
    "\n",
    "                            # Extract the part of the sequence corresponding to the flattened grid\n",
    "                            # ARC_INPUT_FLAT_DIM = MAX_GRID_SIZE[0] * MAX_GRID_SIZE[1]\n",
    "                            if predicted_byte_sequence.shape[1] >= ARC_INPUT_FLAT_DIM:\n",
    "                                preds_flat_bytes = predicted_byte_sequence[0, :ARC_INPUT_FLAT_DIM] # Get first item in batch, first ARC_INPUT_FLAT_DIM bytes\n",
    "                                # Convert byte values (0-9 for ARC symbols) to long tensor and reshape\n",
    "                                preds_grid = preds_flat_bytes.view(MAX_GRID_SIZE).long().cpu().numpy()\n",
    "                            else:\n",
    "                                print(f\"Warning: Generated byte sequence too short ({predicted_byte_sequence.shape[1]} vs {ARC_INPUT_FLAT_DIM}). Using zeros.\")\n",
    "                                preds_grid = np.zeros(MAX_GRID_SIZE, dtype=int)\n",
    "                        \n",
    "                        # Unpad to original dimensions\n",
    "                        h, w = original_dims\n",
    "                        final_pred = preds_grid[:h, :w]\n",
    "                        final_target = target_grid_np[:h, :w]\n",
    "\n",
    "                        if np.array_equal(final_pred, final_target):\n",
    "                            test_input_solved = True\n",
    "                            break\n",
    "\n",
    "                    if not test_input_solved:\n",
    "                        task_solved_overall = False\n",
    "                        break\n",
    "                \n",
    "                if task_solved_overall:\n",
    "                    solved_tasks += 1\n",
    "                    print(f\"  Task {task_idx + 1}/{len(arc_eval_loader)} ({current_task_data.get('id', 'N/A')}): SOLVED\")\n",
    "                else:\n",
    "                    print(f\"  Task {task_idx + 1}/{len(arc_eval_loader)} ({current_task_data.get('id', 'N/A')}): FAILED\")\n",
    "\n",
    "        if total_tasks > 0:\n",
    "            accuracy = (solved_tasks / total_tasks) * 100\n",
    "            summary = f\"ARC-AGI-2 Evaluation Summary:\\n  Total tasks evaluated: {total_tasks}\\n  Tasks solved: {solved_tasks}\\n  Accuracy: {accuracy:.2f}%\"\n",
    "            print(f\"\\n{summary}\")\n",
    "            with open('arc_agi_2_evaluation_summary.txt', 'w') as f:\n",
    "                f.write(summary)\n",
    "        else:\n",
    "            print(\"\\nARC-AGI-2 Evaluation: No tasks were evaluated.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during ARC-AGI-2 evaluation: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\nðŸ”¬ ARC-AGI-2 Evaluation Phase Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
